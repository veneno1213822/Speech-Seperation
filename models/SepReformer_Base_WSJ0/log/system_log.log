2024-10-28 18:14:46.092 | DEBUG    | __main__:<module>:32 - Entering 'main' (args=(Namespace(model='SepReformer_Base_WSJ0', engine_mode='infer_sample', sample_file='./sample_wav/sample_WSJ.wav', out_wav_dir='./sample_out/'),), kwargs={})
2024-10-28 18:14:46.092 | DEBUG    | models.SepReformer_Base_WSJ0.main:main:20 - Entering 'parse_yaml' (args=('D:\\PythonProject-RequiredCourse\\4rdâ†‘ SyntheticDesign_AIalgorithm_WUJIASONG\\SepReformer-main\\models\\SepReformer_Base_WSJ0\\configs.yaml',), kwargs={})
2024-10-28 18:14:46.108 | DEBUG    | models.SepReformer_Base_WSJ0.main:main:20 - Exiting 'parse_yaml' (result={'project': '[Project] SepReformer', 'notes': 'SepReformer final version', 'config': {'dataset': {'max_len': 32000, 'sampling_rate': 8000, 'scp_dir': 'data/scp_ss_8k', 'train': {'mixture': 'tr_mix.scp', 'spk1': 'tr_s1.scp', 'spk2': 'tr_s2.scp', 'dynamic_mixing': False}, 'valid': {'mixture': 'cv_mix.scp', 'spk1': 'cv_s1.scp', 'spk2': 'cv_s2.scp'}, 'test': {'mixture': 'tt_mix.scp', 'spk1': 'tt_s1.scp', 'spk2': 'tt_s2.scp'}}, 'dataloader': {'batch_size': 2, 'pin_memory': False, 'num_workers': 12, 'drop_last': False}, 'model': {'num_stages': 4, 'num_spks': 2, 'module_audio_enc': {'in_channels': 1, 'out_channels': 256, 'kernel_size': 16, 'stride': 4, 'groups': 1, 'bias': False}, 'module_feature_projector': {'num_channels': 256, 'in_channels': 256, 'out_channels': 128, 'kernel_size': 1, 'bias': False}, 'module_separator': {'num_stages': 4, 'relative_positional_encoding': {'in_channels': 128, 'num_heads': 8, 'maxlen': 2000, 'embed_v': False}, 'enc_stage': {'global_blocks': {'in_channels': 128, 'num_mha_heads': 8, 'dropout_rate': 0.05}, 'local_blocks': {'in_channels': 128, 'kernel_size': 65, 'dropout_rate': 0.05}, 'down_conv_layer': {'in_channels': 128, 'samp_kernel_size': 5}}, 'spk_split_stage': {'in_channels': 128, 'num_spks': 2}, 'simple_fusion': {'out_channels': 128}, 'dec_stage': {'num_spks': 2, 'global_blocks': {'in_channels': 128, 'num_mha_heads': 8, 'dropout_rate': 0.05}, 'local_blocks': {'in_channels': 128, 'kernel_size': 65, 'dropout_rate': 0.05}, 'spk_attention': {'in_channels': 128, 'num_mha_heads': 8, 'dropout_rate': 0.05}}}, 'module_output_layer': {'in_channels': 256, 'out_channels': 128, 'num_spks': 2}, 'module_audio_dec': {'in_channels': 256, 'out_channels': 1, 'kernel_size': 16, 'stride': 4, 'bias': False}}, 'criterion': {'name': ['PIT_SISNR_mag', 'PIT_SISNR_time', 'PIT_SISNRi', 'PIT_SDRi'], 'PIT_SISNR_mag': {'frame_length': 512, 'frame_shift': 128, 'window': 'hann', 'num_stages': 4, 'num_spks': 2, 'scale_inv': True, 'mel_opt': False}, 'PIT_SISNR_time': {'num_spks': 2, 'scale_inv': True}, 'PIT_SISNRi': {'num_spks': 2, 'scale_inv': True}, 'PIT_SDRi': {'dump': 0}}, 'optimizer': {'name': ['AdamW'], 'AdamW': {'lr': 0.001, 'weight_decay': 0.01}}, 'scheduler': {'name': ['ReduceLROnPlateau', 'WarmupConstantSchedule'], 'ReduceLROnPlateau': {'mode': 'min', 'min_lr': 1e-10, 'factor': 0.8, 'patience': 2}, 'WarmupConstantSchedule': {'warmup_steps': 1000}}, 'check_computations': {'dummy_len': 16000}, 'engine': {'max_epoch': 200, 'gpuid': '0', 'mvn': False, 'clip_norm': 5, 'start_scheduling': 50, 'test_epochs': [100, 120, 150, 170]}}})
2024-10-28 18:14:46.109 | DEBUG    | models.SepReformer_Base_WSJ0.main:main:26 - Entering 'get_dataloaders' (args=(Namespace(model='SepReformer_Base_WSJ0', engine_mode='infer_sample', sample_file='./sample_wav/sample_WSJ.wav', out_wav_dir='./sample_out/'), {'max_len': 32000, 'sampling_rate': 8000, 'scp_dir': 'data/scp_ss_8k', 'train': {'mixture': 'tr_mix.scp', 'spk1': 'tr_s1.scp', 'spk2': 'tr_s2.scp', 'dynamic_mixing': False}, 'valid': {'mixture': 'cv_mix.scp', 'spk1': 'cv_s1.scp', 'spk2': 'cv_s2.scp'}, 'test': {'mixture': 'tt_mix.scp', 'spk1': 'tt_s1.scp', 'spk2': 'tt_s2.scp'}}, {'batch_size': 2, 'pin_memory': False, 'num_workers': 12, 'drop_last': False}), kwargs={})
2024-10-28 18:14:46.109 | DEBUG    | models.SepReformer_Base_WSJ0.dataset:get_dataloaders:21 - Entering 'MyDataset' (args=(), kwargs={'max_len': 32000, 'fs': 8000, 'partition': 'train', 'wave_scp_srcs': ['data/scp_ss_8k\\tr_s1.scp', 'data/scp_ss_8k\\tr_s2.scp'], 'wave_scp_mix': 'data/scp_ss_8k\\tr_mix.scp', 'dynamic_mixing': False})
2024-10-28 18:14:46.216 | INFO     | models.SepReformer_Base_WSJ0.dataset:__init__:76 - Create MyDataset for data/scp_ss_8k\tr_mix.scp with 26038 utterances
2024-10-28 18:14:46.217 | DEBUG    | models.SepReformer_Base_WSJ0.dataset:get_dataloaders:21 - Exiting 'MyDataset' (result=<models.SepReformer_Base_WSJ0.dataset.MyDataset object at 0x000002490B148280>)
2024-10-28 18:14:46.217 | DEBUG    | models.SepReformer_Base_WSJ0.dataset:get_dataloaders:21 - Entering 'MyDataset' (args=(), kwargs={'max_len': 32000, 'fs': 8000, 'partition': 'valid', 'wave_scp_srcs': ['data/scp_ss_8k\\cv_s1.scp', 'data/scp_ss_8k\\cv_s2.scp'], 'wave_scp_mix': 'data/scp_ss_8k\\cv_mix.scp', 'dynamic_mixing': False})
2024-10-28 18:14:46.244 | INFO     | models.SepReformer_Base_WSJ0.dataset:__init__:76 - Create MyDataset for data/scp_ss_8k\cv_mix.scp with 6546 utterances
2024-10-28 18:14:46.245 | DEBUG    | models.SepReformer_Base_WSJ0.dataset:get_dataloaders:21 - Exiting 'MyDataset' (result=<models.SepReformer_Base_WSJ0.dataset.MyDataset object at 0x000002490B1481F0>)
2024-10-28 18:14:46.245 | DEBUG    | models.SepReformer_Base_WSJ0.dataset:get_dataloaders:21 - Entering 'MyDataset' (args=(), kwargs={'max_len': 32000, 'fs': 8000, 'partition': 'test', 'wave_scp_srcs': ['data/scp_ss_8k\\tt_s1.scp', 'data/scp_ss_8k\\tt_s2.scp'], 'wave_scp_mix': 'data/scp_ss_8k\\tt_mix.scp', 'dynamic_mixing': False})
2024-10-28 18:14:46.258 | INFO     | models.SepReformer_Base_WSJ0.dataset:__init__:76 - Create MyDataset for data/scp_ss_8k\tt_mix.scp with 3000 utterances
2024-10-28 18:14:46.259 | DEBUG    | models.SepReformer_Base_WSJ0.dataset:get_dataloaders:21 - Exiting 'MyDataset' (result=<models.SepReformer_Base_WSJ0.dataset.MyDataset object at 0x000002490B1484C0>)
2024-10-28 18:14:46.259 | DEBUG    | models.SepReformer_Base_WSJ0.main:main:26 - Exiting 'get_dataloaders' (result={'train': <torch.utils.data.dataloader.DataLoader object at 0x000002490B148130>, 'valid': <torch.utils.data.dataloader.DataLoader object at 0x000002490B148040>, 'test': <torch.utils.data.dataloader.DataLoader object at 0x000002490B148400>})
2024-10-28 18:14:46.259 | DEBUG    | models.SepReformer_Base_WSJ0.main:main:30 - Entering 'Model' (args=(), kwargs={'num_stages': 4, 'num_spks': 2, 'module_audio_enc': {'in_channels': 1, 'out_channels': 256, 'kernel_size': 16, 'stride': 4, 'groups': 1, 'bias': False}, 'module_feature_projector': {'num_channels': 256, 'in_channels': 256, 'out_channels': 128, 'kernel_size': 1, 'bias': False}, 'module_separator': {'num_stages': 4, 'relative_positional_encoding': {'in_channels': 128, 'num_heads': 8, 'maxlen': 2000, 'embed_v': False}, 'enc_stage': {'global_blocks': {'in_channels': 128, 'num_mha_heads': 8, 'dropout_rate': 0.05}, 'local_blocks': {'in_channels': 128, 'kernel_size': 65, 'dropout_rate': 0.05}, 'down_conv_layer': {'in_channels': 128, 'samp_kernel_size': 5}}, 'spk_split_stage': {'in_channels': 128, 'num_spks': 2}, 'simple_fusion': {'out_channels': 128}, 'dec_stage': {'num_spks': 2, 'global_blocks': {'in_channels': 128, 'num_mha_heads': 8, 'dropout_rate': 0.05}, 'local_blocks': {'in_channels': 128, 'kernel_size': 65, 'dropout_rate': 0.05}, 'spk_attention': {'in_channels': 128, 'num_mha_heads': 8, 'dropout_rate': 0.05}}}, 'module_output_layer': {'in_channels': 256, 'out_channels': 128, 'num_spks': 2}, 'module_audio_dec': {'in_channels': 256, 'out_channels': 1, 'kernel_size': 16, 'stride': 4, 'bias': False}})
2024-10-28 18:14:46.401 | DEBUG    | models.SepReformer_Base_WSJ0.main:main:30 - Exiting 'Model' (result=Model(
  (audio_encoder): AudioEncoder(
    (conv1d): Conv1d(1, 256, kernel_size=(16,), stride=(4,), bias=False)
    (gelu): GELU(approximate='none')
  )
  (feature_projector): FeatureProjector(
    (norm): GroupNorm(1, 256, eps=1e-08, affine=True)
    (conv1d): Conv1d(256, 128, kernel_size=(1,), stride=(1,), bias=False)
  )
  (separator): Separator(
    (pos_emb): RelativePositionalEncoding(
      (pe_k): Embedding(4000, 16)
    )
    (enc_stages): ModuleList(
      (0-3): 4 x SepEncStage(
        (g_block_1): GlobalBlock(
          (block): ModuleDict(
            (ega): EGA(
              (block): ModuleDict(
                (self_attn): MultiHeadAttention(
                  (layer_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
                  (linear_q): Linear(in_features=128, out_features=128, bias=True)
                  (linear_k): Linear(in_features=128, out_features=128, bias=True)
                  (linear_v): Linear(in_features=128, out_features=128, bias=True)
                  (linear_out): Linear(in_features=128, out_features=128, bias=True)
                  (dropout): Dropout(p=0.05, inplace=False)
                  (Layer_scale): LayerScale()
                )
                (linear): Sequential(
                  (0): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
                  (1): Linear(in_features=128, out_features=128, bias=True)
                  (2): Sigmoid()
                )
              )
            )
            (gcfn): GCFN(
              (net1): Sequential(
                (0): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
                (1): Linear(in_features=128, out_features=768, bias=True)
              )
              (depthwise): Conv1d(768, 768, kernel_size=(3,), stride=(1,), padding=(1,), groups=768)
              (net2): Sequential(
                (0): GLU(dim=-1)
                (1): Dropout(p=0.05, inplace=False)
                (2): Linear(in_features=384, out_features=128, bias=True)
                (3): Dropout(p=0.05, inplace=False)
              )
              (Layer_scale): LayerScale()
            )
          )
        )
        (l_block_1): LocalBlock(
          (block): ModuleDict(
            (cla): CLA(
              (layer_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=128, out_features=256, bias=True)
              (GLU): GLU(dim=-1)
              (dw_conv_1d): Conv1d(128, 128, kernel_size=(65,), stride=(1,), padding=same, groups=128)
              (linear2): Linear(in_features=128, out_features=256, bias=True)
              (BN): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (linear3): Sequential(
                (0): GELU(approximate='none')
                (1): Linear(in_features=256, out_features=128, bias=True)
                (2): Dropout(p=0.05, inplace=False)
              )
              (Layer_scale): LayerScale()
            )
            (gcfn): GCFN(
              (net1): Sequential(
                (0): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
                (1): Linear(in_features=128, out_features=768, bias=True)
              )
              (depthwise): Conv1d(768, 768, kernel_size=(3,), stride=(1,), padding=(1,), groups=768)
              (net2): Sequential(
                (0): GLU(dim=-1)
                (1): Dropout(p=0.05, inplace=False)
                (2): Linear(in_features=384, out_features=128, bias=True)
                (3): Dropout(p=0.05, inplace=False)
              )
              (Layer_scale): LayerScale()
            )
          )
        )
        (g_block_2): GlobalBlock(
          (block): ModuleDict(
            (ega): EGA(
              (block): ModuleDict(
                (self_attn): MultiHeadAttention(
                  (layer_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
                  (linear_q): Linear(in_features=128, out_features=128, bias=True)
                  (linear_k): Linear(in_features=128, out_features=128, bias=True)
                  (linear_v): Linear(in_features=128, out_features=128, bias=True)
                  (linear_out): Linear(in_features=128, out_features=128, bias=True)
                  (dropout): Dropout(p=0.05, inplace=False)
                  (Layer_scale): LayerScale()
                )
                (linear): Sequential(
                  (0): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
                  (1): Linear(in_features=128, out_features=128, bias=True)
                  (2): Sigmoid()
                )
              )
            )
            (gcfn): GCFN(
              (net1): Sequential(
                (0): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
                (1): Linear(in_features=128, out_features=768, bias=True)
              )
              (depthwise): Conv1d(768, 768, kernel_size=(3,), stride=(1,), padding=(1,), groups=768)
              (net2): Sequential(
                (0): GLU(dim=-1)
                (1): Dropout(p=0.05, inplace=False)
                (2): Linear(in_features=384, out_features=128, bias=True)
                (3): Dropout(p=0.05, inplace=False)
              )
              (Layer_scale): LayerScale()
            )
          )
        )
        (l_block_2): LocalBlock(
          (block): ModuleDict(
            (cla): CLA(
              (layer_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=128, out_features=256, bias=True)
              (GLU): GLU(dim=-1)
              (dw_conv_1d): Conv1d(128, 128, kernel_size=(65,), stride=(1,), padding=same, groups=128)
              (linear2): Linear(in_features=128, out_features=256, bias=True)
              (BN): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (linear3): Sequential(
                (0): GELU(approximate='none')
                (1): Linear(in_features=256, out_features=128, bias=True)
                (2): Dropout(p=0.05, inplace=False)
              )
              (Layer_scale): LayerScale()
            )
            (gcfn): GCFN(
              (net1): Sequential(
                (0): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
                (1): Linear(in_features=128, out_features=768, bias=True)
              )
              (depthwise): Conv1d(768, 768, kernel_size=(3,), stride=(1,), padding=(1,), groups=768)
              (net2): Sequential(
                (0): GLU(dim=-1)
                (1): Dropout(p=0.05, inplace=False)
                (2): Linear(in_features=384, out_features=128, bias=True)
                (3): Dropout(p=0.05, inplace=False)
              )
              (Layer_scale): LayerScale()
            )
          )
        )
        (downconv): DownConvLayer(
          (down_conv): Conv1d(128, 128, kernel_size=(5,), stride=(2,), padding=(2,), groups=128)
          (BN): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (gelu): GELU(approximate='none')
        )
      )
    )
    (bottleneck_G): SepEncStage(
      (g_block_1): GlobalBlock(
        (block): ModuleDict(
          (ega): EGA(
            (block): ModuleDict(
              (self_attn): MultiHeadAttention(
                (layer_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
                (linear_q): Linear(in_features=128, out_features=128, bias=True)
                (linear_k): Linear(in_features=128, out_features=128, bias=True)
                (linear_v): Linear(in_features=128, out_features=128, bias=True)
                (linear_out): Linear(in_features=128, out_features=128, bias=True)
                (dropout): Dropout(p=0.05, inplace=False)
                (Layer_scale): LayerScale()
              )
              (linear): Sequential(
                (0): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
                (1): Linear(in_features=128, out_features=128, bias=True)
                (2): Sigmoid()
              )
            )
          )
          (gcfn): GCFN(
            (net1): Sequential(
              (0): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
              (1): Linear(in_features=128, out_features=768, bias=True)
            )
            (depthwise): Conv1d(768, 768, kernel_size=(3,), stride=(1,), padding=(1,), groups=768)
            (net2): Sequential(
              (0): GLU(dim=-1)
              (1): Dropout(p=0.05, inplace=False)
              (2): Linear(in_features=384, out_features=128, bias=True)
              (3): Dropout(p=0.05, inplace=False)
            )
            (Layer_scale): LayerScale()
          )
        )
      )
      (l_block_1): LocalBlock(
        (block): ModuleDict(
          (cla): CLA(
            (layer_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
            (linear1): Linear(in_features=128, out_features=256, bias=True)
            (GLU): GLU(dim=-1)
            (dw_conv_1d): Conv1d(128, 128, kernel_size=(65,), stride=(1,), padding=same, groups=128)
            (linear2): Linear(in_features=128, out_features=256, bias=True)
            (BN): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (linear3): Sequential(
              (0): GELU(approximate='none')
              (1): Linear(in_features=256, out_features=128, bias=True)
              (2): Dropout(p=0.05, inplace=False)
            )
            (Layer_scale): LayerScale()
          )
          (gcfn): GCFN(
            (net1): Sequential(
              (0): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
              (1): Linear(in_features=128, out_features=768, bias=True)
            )
            (depthwise): Conv1d(768, 768, kernel_size=(3,), stride=(1,), padding=(1,), groups=768)
            (net2): Sequential(
              (0): GLU(dim=-1)
              (1): Dropout(p=0.05, inplace=False)
              (2): Linear(in_features=384, out_features=128, bias=True)
              (3): Dropout(p=0.05, inplace=False)
            )
            (Layer_scale): LayerScale()
          )
        )
      )
      (g_block_2): GlobalBlock(
        (block): ModuleDict(
          (ega): EGA(
            (block): ModuleDict(
              (self_attn): MultiHeadAttention(
                (layer_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
                (linear_q): Linear(in_features=128, out_features=128, bias=True)
                (linear_k): Linear(in_features=128, out_features=128, bias=True)
                (linear_v): Linear(in_features=128, out_features=128, bias=True)
                (linear_out): Linear(in_features=128, out_features=128, bias=True)
                (dropout): Dropout(p=0.05, inplace=False)
                (Layer_scale): LayerScale()
              )
              (linear): Sequential(
                (0): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
                (1): Linear(in_features=128, out_features=128, bias=True)
                (2): Sigmoid()
              )
            )
          )
          (gcfn): GCFN(
            (net1): Sequential(
              (0): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
              (1): Linear(in_features=128, out_features=768, bias=True)
            )
            (depthwise): Conv1d(768, 768, kernel_size=(3,), stride=(1,), padding=(1,), groups=768)
            (net2): Sequential(
              (0): GLU(dim=-1)
              (1): Dropout(p=0.05, inplace=False)
              (2): Linear(in_features=384, out_features=128, bias=True)
              (3): Dropout(p=0.05, inplace=False)
            )
            (Layer_scale): LayerScale()
          )
        )
      )
      (l_block_2): LocalBlock(
        (block): ModuleDict(
          (cla): CLA(
            (layer_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
            (linear1): Linear(in_features=128, out_features=256, bias=True)
            (GLU): GLU(dim=-1)
            (dw_conv_1d): Conv1d(128, 128, kernel_size=(65,), stride=(1,), padding=same, groups=128)
            (linear2): Linear(in_features=128, out_features=256, bias=True)
            (BN): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (linear3): Sequential(
              (0): GELU(approximate='none')
              (1): Linear(in_features=256, out_features=128, bias=True)
              (2): Dropout(p=0.05, inplace=False)
            )
            (Layer_scale): LayerScale()
          )
          (gcfn): GCFN(
            (net1): Sequential(
              (0): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
              (1): Linear(in_features=128, out_features=768, bias=True)
            )
            (depthwise): Conv1d(768, 768, kernel_size=(3,), stride=(1,), padding=(1,), groups=768)
            (net2): Sequential(
              (0): GLU(dim=-1)
              (1): Dropout(p=0.05, inplace=False)
              (2): Linear(in_features=384, out_features=128, bias=True)
              (3): Dropout(p=0.05, inplace=False)
            )
            (Layer_scale): LayerScale()
          )
        )
      )
    )
    (spk_split_block): SpkSplitStage(
      (linear): Sequential(
        (0): Conv1d(128, 1024, kernel_size=(1,), stride=(1,))
        (1): GLU(dim=-2)
        (2): Conv1d(512, 256, kernel_size=(1,), stride=(1,))
      )
      (norm): GroupNorm(1, 128, eps=1e-08, affine=True)
    )
    (simple_fusion): ModuleList(
      (0-3): 4 x Conv1d(256, 128, kernel_size=(1,), stride=(1,))
    )
    (dec_stages): ModuleList(
      (0-3): 4 x SepDecStage(
        (g_block_1): GlobalBlock(
          (block): ModuleDict(
            (ega): EGA(
              (block): ModuleDict(
                (self_attn): MultiHeadAttention(
                  (layer_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
                  (linear_q): Linear(in_features=128, out_features=128, bias=True)
                  (linear_k): Linear(in_features=128, out_features=128, bias=True)
                  (linear_v): Linear(in_features=128, out_features=128, bias=True)
                  (linear_out): Linear(in_features=128, out_features=128, bias=True)
                  (dropout): Dropout(p=0.05, inplace=False)
                  (Layer_scale): LayerScale()
                )
                (linear): Sequential(
                  (0): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
                  (1): Linear(in_features=128, out_features=128, bias=True)
                  (2): Sigmoid()
                )
              )
            )
            (gcfn): GCFN(
              (net1): Sequential(
                (0): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
                (1): Linear(in_features=128, out_features=768, bias=True)
              )
              (depthwise): Conv1d(768, 768, kernel_size=(3,), stride=(1,), padding=(1,), groups=768)
              (net2): Sequential(
                (0): GLU(dim=-1)
                (1): Dropout(p=0.05, inplace=False)
                (2): Linear(in_features=384, out_features=128, bias=True)
                (3): Dropout(p=0.05, inplace=False)
              )
              (Layer_scale): LayerScale()
            )
          )
        )
        (l_block_1): LocalBlock(
          (block): ModuleDict(
            (cla): CLA(
              (layer_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=128, out_features=256, bias=True)
              (GLU): GLU(dim=-1)
              (dw_conv_1d): Conv1d(128, 128, kernel_size=(65,), stride=(1,), padding=same, groups=128)
              (linear2): Linear(in_features=128, out_features=256, bias=True)
              (BN): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (linear3): Sequential(
                (0): GELU(approximate='none')
                (1): Linear(in_features=256, out_features=128, bias=True)
                (2): Dropout(p=0.05, inplace=False)
              )
              (Layer_scale): LayerScale()
            )
            (gcfn): GCFN(
              (net1): Sequential(
                (0): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
                (1): Linear(in_features=128, out_features=768, bias=True)
              )
              (depthwise): Conv1d(768, 768, kernel_size=(3,), stride=(1,), padding=(1,), groups=768)
              (net2): Sequential(
                (0): GLU(dim=-1)
                (1): Dropout(p=0.05, inplace=False)
                (2): Linear(in_features=384, out_features=128, bias=True)
                (3): Dropout(p=0.05, inplace=False)
              )
              (Layer_scale): LayerScale()
            )
          )
        )
        (spk_attn_1): SpkAttention(
          (self_attn): MultiHeadAttention(
            (layer_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
            (linear_q): Linear(in_features=128, out_features=128, bias=True)
            (linear_k): Linear(in_features=128, out_features=128, bias=True)
            (linear_v): Linear(in_features=128, out_features=128, bias=True)
            (linear_out): Linear(in_features=128, out_features=128, bias=True)
            (dropout): Dropout(p=0.05, inplace=False)
            (Layer_scale): LayerScale()
          )
          (feed_forward): GCFN(
            (net1): Sequential(
              (0): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
              (1): Linear(in_features=128, out_features=768, bias=True)
            )
            (depthwise): Conv1d(768, 768, kernel_size=(3,), stride=(1,), padding=(1,), groups=768)
            (net2): Sequential(
              (0): GLU(dim=-1)
              (1): Dropout(p=0.05, inplace=False)
              (2): Linear(in_features=384, out_features=128, bias=True)
              (3): Dropout(p=0.05, inplace=False)
            )
            (Layer_scale): LayerScale()
          )
        )
        (g_block_2): GlobalBlock(
          (block): ModuleDict(
            (ega): EGA(
              (block): ModuleDict(
                (self_attn): MultiHeadAttention(
                  (layer_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
                  (linear_q): Linear(in_features=128, out_features=128, bias=True)
                  (linear_k): Linear(in_features=128, out_features=128, bias=True)
                  (linear_v): Linear(in_features=128, out_features=128, bias=True)
                  (linear_out): Linear(in_features=128, out_features=128, bias=True)
                  (dropout): Dropout(p=0.05, inplace=False)
                  (Layer_scale): LayerScale()
                )
                (linear): Sequential(
                  (0): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
                  (1): Linear(in_features=128, out_features=128, bias=True)
                  (2): Sigmoid()
                )
              )
            )
            (gcfn): GCFN(
              (net1): Sequential(
                (0): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
                (1): Linear(in_features=128, out_features=768, bias=True)
              )
              (depthwise): Conv1d(768, 768, kernel_size=(3,), stride=(1,), padding=(1,), groups=768)
              (net2): Sequential(
                (0): GLU(dim=-1)
                (1): Dropout(p=0.05, inplace=False)
                (2): Linear(in_features=384, out_features=128, bias=True)
                (3): Dropout(p=0.05, inplace=False)
              )
              (Layer_scale): LayerScale()
            )
          )
        )
        (l_block_2): LocalBlock(
          (block): ModuleDict(
            (cla): CLA(
              (layer_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=128, out_features=256, bias=True)
              (GLU): GLU(dim=-1)
              (dw_conv_1d): Conv1d(128, 128, kernel_size=(65,), stride=(1,), padding=same, groups=128)
              (linear2): Linear(in_features=128, out_features=256, bias=True)
              (BN): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (linear3): Sequential(
                (0): GELU(approximate='none')
                (1): Linear(in_features=256, out_features=128, bias=True)
                (2): Dropout(p=0.05, inplace=False)
              )
              (Layer_scale): LayerScale()
            )
            (gcfn): GCFN(
              (net1): Sequential(
                (0): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
                (1): Linear(in_features=128, out_features=768, bias=True)
              )
              (depthwise): Conv1d(768, 768, kernel_size=(3,), stride=(1,), padding=(1,), groups=768)
              (net2): Sequential(
                (0): GLU(dim=-1)
                (1): Dropout(p=0.05, inplace=False)
                (2): Linear(in_features=384, out_features=128, bias=True)
                (3): Dropout(p=0.05, inplace=False)
              )
              (Layer_scale): LayerScale()
            )
          )
        )
        (spk_attn_2): SpkAttention(
          (self_attn): MultiHeadAttention(
            (layer_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
            (linear_q): Linear(in_features=128, out_features=128, bias=True)
            (linear_k): Linear(in_features=128, out_features=128, bias=True)
            (linear_v): Linear(in_features=128, out_features=128, bias=True)
            (linear_out): Linear(in_features=128, out_features=128, bias=True)
            (dropout): Dropout(p=0.05, inplace=False)
            (Layer_scale): LayerScale()
          )
          (feed_forward): GCFN(
            (net1): Sequential(
              (0): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
              (1): Linear(in_features=128, out_features=768, bias=True)
            )
            (depthwise): Conv1d(768, 768, kernel_size=(3,), stride=(1,), padding=(1,), groups=768)
            (net2): Sequential(
              (0): GLU(dim=-1)
              (1): Dropout(p=0.05, inplace=False)
              (2): Linear(in_features=384, out_features=128, bias=True)
              (3): Dropout(p=0.05, inplace=False)
            )
            (Layer_scale): LayerScale()
          )
        )
        (g_block_3): GlobalBlock(
          (block): ModuleDict(
            (ega): EGA(
              (block): ModuleDict(
                (self_attn): MultiHeadAttention(
                  (layer_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
                  (linear_q): Linear(in_features=128, out_features=128, bias=True)
                  (linear_k): Linear(in_features=128, out_features=128, bias=True)
                  (linear_v): Linear(in_features=128, out_features=128, bias=True)
                  (linear_out): Linear(in_features=128, out_features=128, bias=True)
                  (dropout): Dropout(p=0.05, inplace=False)
                  (Layer_scale): LayerScale()
                )
                (linear): Sequential(
                  (0): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
                  (1): Linear(in_features=128, out_features=128, bias=True)
                  (2): Sigmoid()
                )
              )
            )
            (gcfn): GCFN(
              (net1): Sequential(
                (0): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
                (1): Linear(in_features=128, out_features=768, bias=True)
              )
              (depthwise): Conv1d(768, 768, kernel_size=(3,), stride=(1,), padding=(1,), groups=768)
              (net2): Sequential(
                (0): GLU(dim=-1)
                (1): Dropout(p=0.05, inplace=False)
                (2): Linear(in_features=384, out_features=128, bias=True)
                (3): Dropout(p=0.05, inplace=False)
              )
              (Layer_scale): LayerScale()
            )
          )
        )
        (l_block_3): LocalBlock(
          (block): ModuleDict(
            (cla): CLA(
              (layer_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=128, out_features=256, bias=True)
              (GLU): GLU(dim=-1)
              (dw_conv_1d): Conv1d(128, 128, kernel_size=(65,), stride=(1,), padding=same, groups=128)
              (linear2): Linear(in_features=128, out_features=256, bias=True)
              (BN): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (linear3): Sequential(
                (0): GELU(approximate='none')
                (1): Linear(in_features=256, out_features=128, bias=True)
                (2): Dropout(p=0.05, inplace=False)
              )
              (Layer_scale): LayerScale()
            )
            (gcfn): GCFN(
              (net1): Sequential(
                (0): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
                (1): Linear(in_features=128, out_features=768, bias=True)
              )
              (depthwise): Conv1d(768, 768, kernel_size=(3,), stride=(1,), padding=(1,), groups=768)
              (net2): Sequential(
                (0): GLU(dim=-1)
                (1): Dropout(p=0.05, inplace=False)
                (2): Linear(in_features=384, out_features=128, bias=True)
                (3): Dropout(p=0.05, inplace=False)
              )
              (Layer_scale): LayerScale()
            )
          )
        )
        (spk_attn_3): SpkAttention(
          (self_attn): MultiHeadAttention(
            (layer_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
            (linear_q): Linear(in_features=128, out_features=128, bias=True)
            (linear_k): Linear(in_features=128, out_features=128, bias=True)
            (linear_v): Linear(in_features=128, out_features=128, bias=True)
            (linear_out): Linear(in_features=128, out_features=128, bias=True)
            (dropout): Dropout(p=0.05, inplace=False)
            (Layer_scale): LayerScale()
          )
          (feed_forward): GCFN(
            (net1): Sequential(
              (0): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
              (1): Linear(in_features=128, out_features=768, bias=True)
            )
            (depthwise): Conv1d(768, 768, kernel_size=(3,), stride=(1,), padding=(1,), groups=768)
            (net2): Sequential(
              (0): GLU(dim=-1)
              (1): Dropout(p=0.05, inplace=False)
              (2): Linear(in_features=384, out_features=128, bias=True)
              (3): Dropout(p=0.05, inplace=False)
            )
            (Layer_scale): LayerScale()
          )
        )
      )
    )
  )
  (out_layer): OutputLayer(
    (spe_block): Masking(
      (gate_act): ReLU()
    )
    (end_conv1x1): Sequential(
      (0): Linear(in_features=128, out_features=512, bias=True)
      (1): GLU(dim=-1)
      (2): Linear(in_features=256, out_features=256, bias=True)
    )
  )
  (audio_decoder): AudioDecoder(256, 1, kernel_size=(16,), stride=(4,), bias=False)
  (out_layer_bn): ModuleList(
    (0-3): 4 x OutputLayer(
      (spe_block): Masking(
        (gate_act): ReLU()
      )
      (end_conv1x1): Sequential(
        (0): Linear(in_features=128, out_features=512, bias=True)
        (1): GLU(dim=-1)
        (2): Linear(in_features=256, out_features=256, bias=True)
      )
    )
  )
  (decoder_bn): ModuleList(
    (0-3): 4 x AudioDecoder(256, 1, kernel_size=(16,), stride=(4,), bias=False)
  )
))
2024-10-28 18:14:46.413 | DEBUG    | models.SepReformer_Base_WSJ0.main:main:38 - Entering 'CriterionFactory' (args=({'name': ['PIT_SISNR_mag', 'PIT_SISNR_time', 'PIT_SISNRi', 'PIT_SDRi'], 'PIT_SISNR_mag': {'frame_length': 512, 'frame_shift': 128, 'window': 'hann', 'num_stages': 4, 'num_spks': 2, 'scale_inv': True, 'mel_opt': False}, 'PIT_SISNR_time': {'num_spks': 2, 'scale_inv': True}, 'PIT_SISNRi': {'num_spks': 2, 'scale_inv': True}, 'PIT_SDRi': {'dump': 0}}, device(type='cuda', index=0)), kwargs={})
2024-10-28 18:14:46.413 | DEBUG    | models.SepReformer_Base_WSJ0.main:main:38 - Exiting 'CriterionFactory' (result=CriterionFactory(config={'name': ['PIT_SISNR_mag', 'PIT_SISNR_time', 'PIT_SISNRi', 'PIT_SDRi'], 'PIT_SISNR_mag': {'frame_length': 512, 'frame_shift': 128, 'window': 'hann', 'num_stages': 4, 'num_spks': 2, 'scale_inv': True, 'mel_opt': False}, 'PIT_SISNR_time': {'num_spks': 2, 'scale_inv': True}, 'PIT_SISNRi': {'num_spks': 2, 'scale_inv': True}, 'PIT_SDRi': {'dump': 0}}, device=device(type='cuda', index=0)))
2024-10-28 18:14:47.519 | INFO     | utils.util_implement:create_instance:27 - Creating PIT_SISNR_mag instance with args: {'frame_length': 512, 'frame_shift': 128, 'window': 'hann', 'num_stages': 4, 'num_spks': 2, 'scale_inv': True, 'mel_opt': False}
2024-10-28 18:14:47.519 | DEBUG    | utils.util_implement:create_instance:28 - Entering 'PIT_SISNR_mag' (args=(device(type='cuda', index=0),), kwargs={'frame_length': 512, 'frame_shift': 128, 'window': 'hann', 'num_stages': 4, 'num_spks': 2, 'scale_inv': True, 'mel_opt': False})
2024-10-28 18:14:47.519 | DEBUG    | utils.implements.criterions:<listcomp>:132 - Entering 'STFT' (args=(device(type='cuda', index=0), 512, 128, 'hann'), kwargs={})
2024-10-28 18:14:47.727 | DEBUG    | utils.implements.criterions:<listcomp>:132 - Exiting 'STFT' (result=STFT(device=device(type='cuda', index=0), frame_length=512, frame_shift=128, window='hann', K=tensor([[[ 0.0000e+00,  1.3582e-06,  5.4340e-06,  ...,  1.2226e-05,
           5.4340e-06,  1.3582e-06]],

        [[ 0.0000e+00,  1.3581e-06,  5.4324e-06,  ...,  1.2218e-05,
           5.4324e-06,  1.3581e-06]],

        [[ 0.0000e+00,  1.3578e-06,  5.4274e-06,  ...,  1.2193e-05,
           5.4274e-06,  1.3578e-06]],

        ...,

        [[ 0.0000e+00, -3.3333e-08,  2.6663e-07,  ...,  8.9942e-07,
          -2.6663e-07,  3.3333e-08]],

        [[ 0.0000e+00, -1.6668e-08,  1.3336e-07,  ...,  4.5001e-07,
          -1.3336e-07,  1.6668e-08]],

        [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,
           0.0000e+00,  0.0000e+00]]], device='cuda:0'), num_bins=257))
2024-10-28 18:14:47.824 | DEBUG    | utils.implements.criterions:<listcomp>:132 - Entering 'STFT' (args=(device(type='cuda', index=0), 512, 128, 'hann'), kwargs={})
2024-10-28 18:14:47.825 | DEBUG    | utils.implements.criterions:<listcomp>:132 - Exiting 'STFT' (result=STFT(device=device(type='cuda', index=0), frame_length=512, frame_shift=128, window='hann', K=tensor([[[ 0.0000e+00,  1.3582e-06,  5.4340e-06,  ...,  1.2226e-05,
           5.4340e-06,  1.3582e-06]],

        [[ 0.0000e+00,  1.3581e-06,  5.4324e-06,  ...,  1.2218e-05,
           5.4324e-06,  1.3581e-06]],

        [[ 0.0000e+00,  1.3578e-06,  5.4274e-06,  ...,  1.2193e-05,
           5.4274e-06,  1.3578e-06]],

        ...,

        [[ 0.0000e+00, -3.3333e-08,  2.6663e-07,  ...,  8.9942e-07,
          -2.6663e-07,  3.3333e-08]],

        [[ 0.0000e+00, -1.6668e-08,  1.3336e-07,  ...,  4.5001e-07,
          -1.3336e-07,  1.6668e-08]],

        [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,
           0.0000e+00,  0.0000e+00]]], device='cuda:0'), num_bins=257))
2024-10-28 18:14:47.829 | DEBUG    | utils.implements.criterions:<listcomp>:132 - Entering 'STFT' (args=(device(type='cuda', index=0), 512, 128, 'hann'), kwargs={})
2024-10-28 18:14:47.830 | DEBUG    | utils.implements.criterions:<listcomp>:132 - Exiting 'STFT' (result=STFT(device=device(type='cuda', index=0), frame_length=512, frame_shift=128, window='hann', K=tensor([[[ 0.0000e+00,  1.3582e-06,  5.4340e-06,  ...,  1.2226e-05,
           5.4340e-06,  1.3582e-06]],

        [[ 0.0000e+00,  1.3581e-06,  5.4324e-06,  ...,  1.2218e-05,
           5.4324e-06,  1.3581e-06]],

        [[ 0.0000e+00,  1.3578e-06,  5.4274e-06,  ...,  1.2193e-05,
           5.4274e-06,  1.3578e-06]],

        ...,

        [[ 0.0000e+00, -3.3333e-08,  2.6663e-07,  ...,  8.9942e-07,
          -2.6663e-07,  3.3333e-08]],

        [[ 0.0000e+00, -1.6668e-08,  1.3336e-07,  ...,  4.5001e-07,
          -1.3336e-07,  1.6668e-08]],

        [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,
           0.0000e+00,  0.0000e+00]]], device='cuda:0'), num_bins=257))
2024-10-28 18:14:47.834 | DEBUG    | utils.implements.criterions:<listcomp>:132 - Entering 'STFT' (args=(device(type='cuda', index=0), 512, 128, 'hann'), kwargs={})
2024-10-28 18:14:47.835 | DEBUG    | utils.implements.criterions:<listcomp>:132 - Exiting 'STFT' (result=STFT(device=device(type='cuda', index=0), frame_length=512, frame_shift=128, window='hann', K=tensor([[[ 0.0000e+00,  1.3582e-06,  5.4340e-06,  ...,  1.2226e-05,
           5.4340e-06,  1.3582e-06]],

        [[ 0.0000e+00,  1.3581e-06,  5.4324e-06,  ...,  1.2218e-05,
           5.4324e-06,  1.3581e-06]],

        [[ 0.0000e+00,  1.3578e-06,  5.4274e-06,  ...,  1.2193e-05,
           5.4274e-06,  1.3578e-06]],

        ...,

        [[ 0.0000e+00, -3.3333e-08,  2.6663e-07,  ...,  8.9942e-07,
          -2.6663e-07,  3.3333e-08]],

        [[ 0.0000e+00, -1.6668e-08,  1.3336e-07,  ...,  4.5001e-07,
          -1.3336e-07,  1.6668e-08]],

        [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,
           0.0000e+00,  0.0000e+00]]], device='cuda:0'), num_bins=257))
2024-10-28 18:14:47.839 | DEBUG    | utils.util_implement:create_instance:28 - Exiting 'PIT_SISNR_mag' (result=<PIT_SISNR_mag(device=device(type='cuda', index=0), frame_length=512, frame_shift=128, window='hann', num_stages=4, num_spks=2, scale_inv=True, mel_opt=False, stft = [STFT instance for 4 layers], mel_fb=Identity)>)
2024-10-28 18:14:47.839 | INFO     | utils.util_implement:create_instance:27 - Creating PIT_SISNR_time instance with args: {'num_spks': 2, 'scale_inv': True}
2024-10-28 18:14:47.840 | DEBUG    | utils.util_implement:create_instance:28 - Entering 'PIT_SISNR_time' (args=(device(type='cuda', index=0),), kwargs={'num_spks': 2, 'scale_inv': True})
2024-10-28 18:14:47.840 | DEBUG    | utils.util_implement:create_instance:28 - Exiting 'PIT_SISNR_time' (result=<PIT_SISNR_time(device=device(type='cuda', index=0), num_spks=2, scale_inv=True)>)
2024-10-28 18:14:47.840 | INFO     | utils.util_implement:create_instance:27 - Creating PIT_SISNRi instance with args: {'num_spks': 2, 'scale_inv': True}
2024-10-28 18:14:47.840 | DEBUG    | utils.util_implement:create_instance:28 - Entering 'PIT_SISNRi' (args=(device(type='cuda', index=0),), kwargs={'num_spks': 2, 'scale_inv': True})
2024-10-28 18:14:47.840 | DEBUG    | utils.util_implement:create_instance:28 - Exiting 'PIT_SISNRi' (result=<PIT_SISNRi(device=device(type='cuda', index=0), num_spks=2, scale_inv=True)>)
2024-10-28 18:14:47.841 | INFO     | utils.util_implement:create_instance:27 - Creating PIT_SDRi instance with args: {'dump': 0}
2024-10-28 18:14:47.841 | DEBUG    | utils.util_implement:create_instance:28 - Entering 'PIT_SDRi' (args=(device(type='cuda', index=0),), kwargs={'dump': 0})
2024-10-28 18:14:47.841 | DEBUG    | utils.util_implement:create_instance:28 - Exiting 'PIT_SDRi' (result=<PIT_SDRi(device=device(type='cuda', index=0), dump=0)>)
2024-10-28 18:14:47.841 | DEBUG    | models.SepReformer_Base_WSJ0.main:main:39 - Entering 'OptimizerFactory' (args=({'name': ['AdamW'], 'AdamW': {'lr': 0.001, 'weight_decay': 0.01}}, <generator object Module.parameters at 0x00000249103C20A0>), kwargs={})
2024-10-28 18:14:47.841 | DEBUG    | models.SepReformer_Base_WSJ0.main:main:39 - Exiting 'OptimizerFactory' (result=OptimizerFactory(config={'name': ['AdamW'], 'AdamW': {'lr': 0.001, 'weight_decay': 0.01}}, parameters_policy=<generator object Module.parameters at 0x00000249103C20A0>))
2024-10-28 18:14:47.842 | INFO     | utils.util_implement:create_instance:27 - Creating AdamW instance with args: {'lr': 0.001, 'weight_decay': 0.01}
2024-10-28 18:14:47.848 | DEBUG    | models.SepReformer_Base_WSJ0.main:main:40 - Entering 'SchedulerFactory' (args=({'name': ['ReduceLROnPlateau', 'WarmupConstantSchedule'], 'ReduceLROnPlateau': {'mode': 'min', 'min_lr': 1e-10, 'factor': 0.8, 'patience': 2}, 'WarmupConstantSchedule': {'warmup_steps': 1000}}, [AdamW (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0.01
)]), kwargs={})
2024-10-28 18:14:47.848 | DEBUG    | models.SepReformer_Base_WSJ0.main:main:40 - Exiting 'SchedulerFactory' (result=SchedulerFactory(config={'name': ['ReduceLROnPlateau', 'WarmupConstantSchedule'], 'ReduceLROnPlateau': {'mode': 'min', 'min_lr': 1e-10, 'factor': 0.8, 'patience': 2}, 'WarmupConstantSchedule': {'warmup_steps': 1000}}, optimizers=[AdamW (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0.01
)]))
2024-10-28 18:14:47.848 | INFO     | utils.util_implement:create_instance:27 - Creating ReduceLROnPlateau instance with args: {'mode': 'min', 'min_lr': 1e-10, 'factor': 0.8, 'patience': 2}
2024-10-28 18:14:47.851 | INFO     | utils.util_implement:create_instance:27 - Creating WarmupConstantSchedule instance with args: {'warmup_steps': 1000}
2024-10-28 18:14:47.851 | DEBUG    | utils.util_implement:create_instance:28 - Entering 'WarmupConstantSchedule' (args=(AdamW (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0.01
),), kwargs={'warmup_steps': 1000})
2024-10-28 18:14:47.851 | DEBUG    | utils.util_implement:create_instance:28 - Exiting 'WarmupConstantSchedule' (result=<WarmupConstantSchedule(optimizer=AdamW (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.001
    lr: 0.0
    maximize: False
    weight_decay: 0.01
), warmup_steps=1000, last_epoch=0, lr_lambda = <function WarmupConstantSchedule.__post_init__.<locals>.lr_lambda at 0x000002490B122B00>)>)
2024-10-28 18:14:47.852 | DEBUG    | models.SepReformer_Base_WSJ0.main:main:43 - Entering 'Engine' (args=(Namespace(model='SepReformer_Base_WSJ0', engine_mode='infer_sample', sample_file='./sample_wav/sample_WSJ.wav', out_wav_dir='./sample_out/'), {'dataset': {'max_len': 32000, 'sampling_rate': 8000, 'scp_dir': 'data/scp_ss_8k', 'train': {'mixture': 'tr_mix.scp', 'spk1': 'tr_s1.scp', 'spk2': 'tr_s2.scp', 'dynamic_mixing': False}, 'valid': {'mixture': 'cv_mix.scp', 'spk1': 'cv_s1.scp', 'spk2': 'cv_s2.scp'}, 'test': {'mixture': 'tt_mix.scp', 'spk1': 'tt_s1.scp', 'spk2': 'tt_s2.scp'}}, 'dataloader': {'batch_size': 2, 'pin_memory': False, 'num_workers': 12, 'drop_last': False}, 'model': {'num_stages': 4, 'num_spks': 2, 'module_audio_enc': {'in_channels': 1, 'out_channels': 256, 'kernel_size': 16, 'stride': 4, 'groups': 1, 'bias': False}, 'module_feature_projector': {'num_channels': 256, 'in_channels': 256, 'out_channels': 128, 'kernel_size': 1, 'bias': False}, 'module_separator': {'num_stages': 4, 'relative_positional_encoding': {'in_channels': 128, 'num_heads': 8, 'maxlen': 2000, 'embed_v': False}, 'enc_stage': {'global_blocks': {'in_channels': 128, 'num_mha_heads': 8, 'dropout_rate': 0.05}, 'local_blocks': {'in_channels': 128, 'kernel_size': 65, 'dropout_rate': 0.05}, 'down_conv_layer': {'in_channels': 128, 'samp_kernel_size': 5}}, 'spk_split_stage': {'in_channels': 128, 'num_spks': 2}, 'simple_fusion': {'out_channels': 128}, 'dec_stage': {'num_spks': 2, 'global_blocks': {'in_channels': 128, 'num_mha_heads': 8, 'dropout_rate': 0.05}, 'local_blocks': {'in_channels': 128, 'kernel_size': 65, 'dropout_rate': 0.05}, 'spk_attention': {'in_channels': 128, 'num_mha_heads': 8, 'dropout_rate': 0.05}}}, 'module_output_layer': {'in_channels': 256, 'out_channels': 128, 'num_spks': 2}, 'module_audio_dec': {'in_channels': 256, 'out_channels': 1, 'kernel_size': 16, 'stride': 4, 'bias': False}}, 'criterion': {'name': ['PIT_SISNR_mag', 'PIT_SISNR_time', 'PIT_SISNRi', 'PIT_SDRi'], 'PIT_SISNR_mag': {'frame_length': 512, 'frame_shift': 128, 'window': 'hann', 'num_stages': 4, 'num_spks': 2, 'scale_inv': True, 'mel_opt': False}, 'PIT_SISNR_time': {'num_spks': 2, 'scale_inv': True}, 'PIT_SISNRi': {'num_spks': 2, 'scale_inv': True}, 'PIT_SDRi': {'dump': 0}}, 'optimizer': {'name': ['AdamW'], 'AdamW': {'lr': 0.001, 'weight_decay': 0.01}}, 'scheduler': {'name': ['ReduceLROnPlateau', 'WarmupConstantSchedule'], 'ReduceLROnPlateau': {'mode': 'min', 'min_lr': 1e-10, 'factor': 0.8, 'patience': 2}, 'WarmupConstantSchedule': {'warmup_steps': 1000}}, 'check_computations': {'dummy_len': 16000}, 'engine': {'max_epoch': 200, 'gpuid': '0', 'mvn': False, 'clip_norm': 5, 'start_scheduling': 50, 'test_epochs': [100, 120, 150, 170]}}, Model(
  (audio_encoder): AudioEncoder(
    (conv1d): Conv1d(1, 256, kernel_size=(16,), stride=(4,), bias=False)
    (gelu): GELU(approximate='none')
  )
  (feature_projector): FeatureProjector(
    (norm): GroupNorm(1, 256, eps=1e-08, affine=True)
    (conv1d): Conv1d(256, 128, kernel_size=(1,), stride=(1,), bias=False)
  )
  (separator): Separator(
    (pos_emb): RelativePositionalEncoding(
      (pe_k): Embedding(4000, 16)
    )
    (enc_stages): ModuleList(
      (0-3): 4 x SepEncStage(
        (g_block_1): GlobalBlock(
          (block): ModuleDict(
            (ega): EGA(
              (block): ModuleDict(
                (self_attn): MultiHeadAttention(
                  (layer_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
                  (linear_q): Linear(in_features=128, out_features=128, bias=True)
                  (linear_k): Linear(in_features=128, out_features=128, bias=True)
                  (linear_v): Linear(in_features=128, out_features=128, bias=True)
                  (linear_out): Linear(in_features=128, out_features=128, bias=True)
                  (dropout): Dropout(p=0.05, inplace=False)
                  (Layer_scale): LayerScale()
                )
                (linear): Sequential(
                  (0): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
                  (1): Linear(in_features=128, out_features=128, bias=True)
                  (2): Sigmoid()
                )
              )
            )
            (gcfn): GCFN(
              (net1): Sequential(
                (0): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
                (1): Linear(in_features=128, out_features=768, bias=True)
              )
              (depthwise): Conv1d(768, 768, kernel_size=(3,), stride=(1,), padding=(1,), groups=768)
              (net2): Sequential(
                (0): GLU(dim=-1)
                (1): Dropout(p=0.05, inplace=False)
                (2): Linear(in_features=384, out_features=128, bias=True)
                (3): Dropout(p=0.05, inplace=False)
              )
              (Layer_scale): LayerScale()
            )
          )
        )
        (l_block_1): LocalBlock(
          (block): ModuleDict(
            (cla): CLA(
              (layer_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=128, out_features=256, bias=True)
              (GLU): GLU(dim=-1)
              (dw_conv_1d): Conv1d(128, 128, kernel_size=(65,), stride=(1,), padding=same, groups=128)
              (linear2): Linear(in_features=128, out_features=256, bias=True)
              (BN): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (linear3): Sequential(
                (0): GELU(approximate='none')
                (1): Linear(in_features=256, out_features=128, bias=True)
                (2): Dropout(p=0.05, inplace=False)
              )
              (Layer_scale): LayerScale()
            )
            (gcfn): GCFN(
              (net1): Sequential(
                (0): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
                (1): Linear(in_features=128, out_features=768, bias=True)
              )
              (depthwise): Conv1d(768, 768, kernel_size=(3,), stride=(1,), padding=(1,), groups=768)
              (net2): Sequential(
                (0): GLU(dim=-1)
                (1): Dropout(p=0.05, inplace=False)
                (2): Linear(in_features=384, out_features=128, bias=True)
                (3): Dropout(p=0.05, inplace=False)
              )
              (Layer_scale): LayerScale()
            )
          )
        )
        (g_block_2): GlobalBlock(
          (block): ModuleDict(
            (ega): EGA(
              (block): ModuleDict(
                (self_attn): MultiHeadAttention(
                  (layer_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
                  (linear_q): Linear(in_features=128, out_features=128, bias=True)
                  (linear_k): Linear(in_features=128, out_features=128, bias=True)
                  (linear_v): Linear(in_features=128, out_features=128, bias=True)
                  (linear_out): Linear(in_features=128, out_features=128, bias=True)
                  (dropout): Dropout(p=0.05, inplace=False)
                  (Layer_scale): LayerScale()
                )
                (linear): Sequential(
                  (0): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
                  (1): Linear(in_features=128, out_features=128, bias=True)
                  (2): Sigmoid()
                )
              )
            )
            (gcfn): GCFN(
              (net1): Sequential(
                (0): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
                (1): Linear(in_features=128, out_features=768, bias=True)
              )
              (depthwise): Conv1d(768, 768, kernel_size=(3,), stride=(1,), padding=(1,), groups=768)
              (net2): Sequential(
                (0): GLU(dim=-1)
                (1): Dropout(p=0.05, inplace=False)
                (2): Linear(in_features=384, out_features=128, bias=True)
                (3): Dropout(p=0.05, inplace=False)
              )
              (Layer_scale): LayerScale()
            )
          )
        )
        (l_block_2): LocalBlock(
          (block): ModuleDict(
            (cla): CLA(
              (layer_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=128, out_features=256, bias=True)
              (GLU): GLU(dim=-1)
              (dw_conv_1d): Conv1d(128, 128, kernel_size=(65,), stride=(1,), padding=same, groups=128)
              (linear2): Linear(in_features=128, out_features=256, bias=True)
              (BN): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (linear3): Sequential(
                (0): GELU(approximate='none')
                (1): Linear(in_features=256, out_features=128, bias=True)
                (2): Dropout(p=0.05, inplace=False)
              )
              (Layer_scale): LayerScale()
            )
            (gcfn): GCFN(
              (net1): Sequential(
                (0): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
                (1): Linear(in_features=128, out_features=768, bias=True)
              )
              (depthwise): Conv1d(768, 768, kernel_size=(3,), stride=(1,), padding=(1,), groups=768)
              (net2): Sequential(
                (0): GLU(dim=-1)
                (1): Dropout(p=0.05, inplace=False)
                (2): Linear(in_features=384, out_features=128, bias=True)
                (3): Dropout(p=0.05, inplace=False)
              )
              (Layer_scale): LayerScale()
            )
          )
        )
        (downconv): DownConvLayer(
          (down_conv): Conv1d(128, 128, kernel_size=(5,), stride=(2,), padding=(2,), groups=128)
          (BN): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (gelu): GELU(approximate='none')
        )
      )
    )
    (bottleneck_G): SepEncStage(
      (g_block_1): GlobalBlock(
        (block): ModuleDict(
          (ega): EGA(
            (block): ModuleDict(
              (self_attn): MultiHeadAttention(
                (layer_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
                (linear_q): Linear(in_features=128, out_features=128, bias=True)
                (linear_k): Linear(in_features=128, out_features=128, bias=True)
                (linear_v): Linear(in_features=128, out_features=128, bias=True)
                (linear_out): Linear(in_features=128, out_features=128, bias=True)
                (dropout): Dropout(p=0.05, inplace=False)
                (Layer_scale): LayerScale()
              )
              (linear): Sequential(
                (0): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
                (1): Linear(in_features=128, out_features=128, bias=True)
                (2): Sigmoid()
              )
            )
          )
          (gcfn): GCFN(
            (net1): Sequential(
              (0): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
              (1): Linear(in_features=128, out_features=768, bias=True)
            )
            (depthwise): Conv1d(768, 768, kernel_size=(3,), stride=(1,), padding=(1,), groups=768)
            (net2): Sequential(
              (0): GLU(dim=-1)
              (1): Dropout(p=0.05, inplace=False)
              (2): Linear(in_features=384, out_features=128, bias=True)
              (3): Dropout(p=0.05, inplace=False)
            )
            (Layer_scale): LayerScale()
          )
        )
      )
      (l_block_1): LocalBlock(
        (block): ModuleDict(
          (cla): CLA(
            (layer_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
            (linear1): Linear(in_features=128, out_features=256, bias=True)
            (GLU): GLU(dim=-1)
            (dw_conv_1d): Conv1d(128, 128, kernel_size=(65,), stride=(1,), padding=same, groups=128)
            (linear2): Linear(in_features=128, out_features=256, bias=True)
            (BN): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (linear3): Sequential(
              (0): GELU(approximate='none')
              (1): Linear(in_features=256, out_features=128, bias=True)
              (2): Dropout(p=0.05, inplace=False)
            )
            (Layer_scale): LayerScale()
          )
          (gcfn): GCFN(
            (net1): Sequential(
              (0): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
              (1): Linear(in_features=128, out_features=768, bias=True)
            )
            (depthwise): Conv1d(768, 768, kernel_size=(3,), stride=(1,), padding=(1,), groups=768)
            (net2): Sequential(
              (0): GLU(dim=-1)
              (1): Dropout(p=0.05, inplace=False)
              (2): Linear(in_features=384, out_features=128, bias=True)
              (3): Dropout(p=0.05, inplace=False)
            )
            (Layer_scale): LayerScale()
          )
        )
      )
      (g_block_2): GlobalBlock(
        (block): ModuleDict(
          (ega): EGA(
            (block): ModuleDict(
              (self_attn): MultiHeadAttention(
                (layer_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
                (linear_q): Linear(in_features=128, out_features=128, bias=True)
                (linear_k): Linear(in_features=128, out_features=128, bias=True)
                (linear_v): Linear(in_features=128, out_features=128, bias=True)
                (linear_out): Linear(in_features=128, out_features=128, bias=True)
                (dropout): Dropout(p=0.05, inplace=False)
                (Layer_scale): LayerScale()
              )
              (linear): Sequential(
                (0): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
                (1): Linear(in_features=128, out_features=128, bias=True)
                (2): Sigmoid()
              )
            )
          )
          (gcfn): GCFN(
            (net1): Sequential(
              (0): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
              (1): Linear(in_features=128, out_features=768, bias=True)
            )
            (depthwise): Conv1d(768, 768, kernel_size=(3,), stride=(1,), padding=(1,), groups=768)
            (net2): Sequential(
              (0): GLU(dim=-1)
              (1): Dropout(p=0.05, inplace=False)
              (2): Linear(in_features=384, out_features=128, bias=True)
              (3): Dropout(p=0.05, inplace=False)
            )
            (Layer_scale): LayerScale()
          )
        )
      )
      (l_block_2): LocalBlock(
        (block): ModuleDict(
          (cla): CLA(
            (layer_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
            (linear1): Linear(in_features=128, out_features=256, bias=True)
            (GLU): GLU(dim=-1)
            (dw_conv_1d): Conv1d(128, 128, kernel_size=(65,), stride=(1,), padding=same, groups=128)
            (linear2): Linear(in_features=128, out_features=256, bias=True)
            (BN): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (linear3): Sequential(
              (0): GELU(approximate='none')
              (1): Linear(in_features=256, out_features=128, bias=True)
              (2): Dropout(p=0.05, inplace=False)
            )
            (Layer_scale): LayerScale()
          )
          (gcfn): GCFN(
            (net1): Sequential(
              (0): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
              (1): Linear(in_features=128, out_features=768, bias=True)
            )
            (depthwise): Conv1d(768, 768, kernel_size=(3,), stride=(1,), padding=(1,), groups=768)
            (net2): Sequential(
              (0): GLU(dim=-1)
              (1): Dropout(p=0.05, inplace=False)
              (2): Linear(in_features=384, out_features=128, bias=True)
              (3): Dropout(p=0.05, inplace=False)
            )
            (Layer_scale): LayerScale()
          )
        )
      )
    )
    (spk_split_block): SpkSplitStage(
      (linear): Sequential(
        (0): Conv1d(128, 1024, kernel_size=(1,), stride=(1,))
        (1): GLU(dim=-2)
        (2): Conv1d(512, 256, kernel_size=(1,), stride=(1,))
      )
      (norm): GroupNorm(1, 128, eps=1e-08, affine=True)
    )
    (simple_fusion): ModuleList(
      (0-3): 4 x Conv1d(256, 128, kernel_size=(1,), stride=(1,))
    )
    (dec_stages): ModuleList(
      (0-3): 4 x SepDecStage(
        (g_block_1): GlobalBlock(
          (block): ModuleDict(
            (ega): EGA(
              (block): ModuleDict(
                (self_attn): MultiHeadAttention(
                  (layer_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
                  (linear_q): Linear(in_features=128, out_features=128, bias=True)
                  (linear_k): Linear(in_features=128, out_features=128, bias=True)
                  (linear_v): Linear(in_features=128, out_features=128, bias=True)
                  (linear_out): Linear(in_features=128, out_features=128, bias=True)
                  (dropout): Dropout(p=0.05, inplace=False)
                  (Layer_scale): LayerScale()
                )
                (linear): Sequential(
                  (0): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
                  (1): Linear(in_features=128, out_features=128, bias=True)
                  (2): Sigmoid()
                )
              )
            )
            (gcfn): GCFN(
              (net1): Sequential(
                (0): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
                (1): Linear(in_features=128, out_features=768, bias=True)
              )
              (depthwise): Conv1d(768, 768, kernel_size=(3,), stride=(1,), padding=(1,), groups=768)
              (net2): Sequential(
                (0): GLU(dim=-1)
                (1): Dropout(p=0.05, inplace=False)
                (2): Linear(in_features=384, out_features=128, bias=True)
                (3): Dropout(p=0.05, inplace=False)
              )
              (Layer_scale): LayerScale()
            )
          )
        )
        (l_block_1): LocalBlock(
          (block): ModuleDict(
            (cla): CLA(
              (layer_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=128, out_features=256, bias=True)
              (GLU): GLU(dim=-1)
              (dw_conv_1d): Conv1d(128, 128, kernel_size=(65,), stride=(1,), padding=same, groups=128)
              (linear2): Linear(in_features=128, out_features=256, bias=True)
              (BN): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (linear3): Sequential(
                (0): GELU(approximate='none')
                (1): Linear(in_features=256, out_features=128, bias=True)
                (2): Dropout(p=0.05, inplace=False)
              )
              (Layer_scale): LayerScale()
            )
            (gcfn): GCFN(
              (net1): Sequential(
                (0): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
                (1): Linear(in_features=128, out_features=768, bias=True)
              )
              (depthwise): Conv1d(768, 768, kernel_size=(3,), stride=(1,), padding=(1,), groups=768)
              (net2): Sequential(
                (0): GLU(dim=-1)
                (1): Dropout(p=0.05, inplace=False)
                (2): Linear(in_features=384, out_features=128, bias=True)
                (3): Dropout(p=0.05, inplace=False)
              )
              (Layer_scale): LayerScale()
            )
          )
        )
        (spk_attn_1): SpkAttention(
          (self_attn): MultiHeadAttention(
            (layer_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
            (linear_q): Linear(in_features=128, out_features=128, bias=True)
            (linear_k): Linear(in_features=128, out_features=128, bias=True)
            (linear_v): Linear(in_features=128, out_features=128, bias=True)
            (linear_out): Linear(in_features=128, out_features=128, bias=True)
            (dropout): Dropout(p=0.05, inplace=False)
            (Layer_scale): LayerScale()
          )
          (feed_forward): GCFN(
            (net1): Sequential(
              (0): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
              (1): Linear(in_features=128, out_features=768, bias=True)
            )
            (depthwise): Conv1d(768, 768, kernel_size=(3,), stride=(1,), padding=(1,), groups=768)
            (net2): Sequential(
              (0): GLU(dim=-1)
              (1): Dropout(p=0.05, inplace=False)
              (2): Linear(in_features=384, out_features=128, bias=True)
              (3): Dropout(p=0.05, inplace=False)
            )
            (Layer_scale): LayerScale()
          )
        )
        (g_block_2): GlobalBlock(
          (block): ModuleDict(
            (ega): EGA(
              (block): ModuleDict(
                (self_attn): MultiHeadAttention(
                  (layer_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
                  (linear_q): Linear(in_features=128, out_features=128, bias=True)
                  (linear_k): Linear(in_features=128, out_features=128, bias=True)
                  (linear_v): Linear(in_features=128, out_features=128, bias=True)
                  (linear_out): Linear(in_features=128, out_features=128, bias=True)
                  (dropout): Dropout(p=0.05, inplace=False)
                  (Layer_scale): LayerScale()
                )
                (linear): Sequential(
                  (0): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
                  (1): Linear(in_features=128, out_features=128, bias=True)
                  (2): Sigmoid()
                )
              )
            )
            (gcfn): GCFN(
              (net1): Sequential(
                (0): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
                (1): Linear(in_features=128, out_features=768, bias=True)
              )
              (depthwise): Conv1d(768, 768, kernel_size=(3,), stride=(1,), padding=(1,), groups=768)
              (net2): Sequential(
                (0): GLU(dim=-1)
                (1): Dropout(p=0.05, inplace=False)
                (2): Linear(in_features=384, out_features=128, bias=True)
                (3): Dropout(p=0.05, inplace=False)
              )
              (Layer_scale): LayerScale()
            )
          )
        )
        (l_block_2): LocalBlock(
          (block): ModuleDict(
            (cla): CLA(
              (layer_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=128, out_features=256, bias=True)
              (GLU): GLU(dim=-1)
              (dw_conv_1d): Conv1d(128, 128, kernel_size=(65,), stride=(1,), padding=same, groups=128)
              (linear2): Linear(in_features=128, out_features=256, bias=True)
              (BN): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (linear3): Sequential(
                (0): GELU(approximate='none')
                (1): Linear(in_features=256, out_features=128, bias=True)
                (2): Dropout(p=0.05, inplace=False)
              )
              (Layer_scale): LayerScale()
            )
            (gcfn): GCFN(
              (net1): Sequential(
                (0): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
                (1): Linear(in_features=128, out_features=768, bias=True)
              )
              (depthwise): Conv1d(768, 768, kernel_size=(3,), stride=(1,), padding=(1,), groups=768)
              (net2): Sequential(
                (0): GLU(dim=-1)
                (1): Dropout(p=0.05, inplace=False)
                (2): Linear(in_features=384, out_features=128, bias=True)
                (3): Dropout(p=0.05, inplace=False)
              )
              (Layer_scale): LayerScale()
            )
          )
        )
        (spk_attn_2): SpkAttention(
          (self_attn): MultiHeadAttention(
            (layer_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
            (linear_q): Linear(in_features=128, out_features=128, bias=True)
            (linear_k): Linear(in_features=128, out_features=128, bias=True)
            (linear_v): Linear(in_features=128, out_features=128, bias=True)
            (linear_out): Linear(in_features=128, out_features=128, bias=True)
            (dropout): Dropout(p=0.05, inplace=False)
            (Layer_scale): LayerScale()
          )
          (feed_forward): GCFN(
            (net1): Sequential(
              (0): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
              (1): Linear(in_features=128, out_features=768, bias=True)
            )
            (depthwise): Conv1d(768, 768, kernel_size=(3,), stride=(1,), padding=(1,), groups=768)
            (net2): Sequential(
              (0): GLU(dim=-1)
              (1): Dropout(p=0.05, inplace=False)
              (2): Linear(in_features=384, out_features=128, bias=True)
              (3): Dropout(p=0.05, inplace=False)
            )
            (Layer_scale): LayerScale()
          )
        )
        (g_block_3): GlobalBlock(
          (block): ModuleDict(
            (ega): EGA(
              (block): ModuleDict(
                (self_attn): MultiHeadAttention(
                  (layer_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
                  (linear_q): Linear(in_features=128, out_features=128, bias=True)
                  (linear_k): Linear(in_features=128, out_features=128, bias=True)
                  (linear_v): Linear(in_features=128, out_features=128, bias=True)
                  (linear_out): Linear(in_features=128, out_features=128, bias=True)
                  (dropout): Dropout(p=0.05, inplace=False)
                  (Layer_scale): LayerScale()
                )
                (linear): Sequential(
                  (0): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
                  (1): Linear(in_features=128, out_features=128, bias=True)
                  (2): Sigmoid()
                )
              )
            )
            (gcfn): GCFN(
              (net1): Sequential(
                (0): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
                (1): Linear(in_features=128, out_features=768, bias=True)
              )
              (depthwise): Conv1d(768, 768, kernel_size=(3,), stride=(1,), padding=(1,), groups=768)
              (net2): Sequential(
                (0): GLU(dim=-1)
                (1): Dropout(p=0.05, inplace=False)
                (2): Linear(in_features=384, out_features=128, bias=True)
                (3): Dropout(p=0.05, inplace=False)
              )
              (Layer_scale): LayerScale()
            )
          )
        )
        (l_block_3): LocalBlock(
          (block): ModuleDict(
            (cla): CLA(
              (layer_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=128, out_features=256, bias=True)
              (GLU): GLU(dim=-1)
              (dw_conv_1d): Conv1d(128, 128, kernel_size=(65,), stride=(1,), padding=same, groups=128)
              (linear2): Linear(in_features=128, out_features=256, bias=True)
              (BN): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (linear3): Sequential(
                (0): GELU(approximate='none')
                (1): Linear(in_features=256, out_features=128, bias=True)
                (2): Dropout(p=0.05, inplace=False)
              )
              (Layer_scale): LayerScale()
            )
            (gcfn): GCFN(
              (net1): Sequential(
                (0): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
                (1): Linear(in_features=128, out_features=768, bias=True)
              )
              (depthwise): Conv1d(768, 768, kernel_size=(3,), stride=(1,), padding=(1,), groups=768)
              (net2): Sequential(
                (0): GLU(dim=-1)
                (1): Dropout(p=0.05, inplace=False)
                (2): Linear(in_features=384, out_features=128, bias=True)
                (3): Dropout(p=0.05, inplace=False)
              )
              (Layer_scale): LayerScale()
            )
          )
        )
        (spk_attn_3): SpkAttention(
          (self_attn): MultiHeadAttention(
            (layer_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
            (linear_q): Linear(in_features=128, out_features=128, bias=True)
            (linear_k): Linear(in_features=128, out_features=128, bias=True)
            (linear_v): Linear(in_features=128, out_features=128, bias=True)
            (linear_out): Linear(in_features=128, out_features=128, bias=True)
            (dropout): Dropout(p=0.05, inplace=False)
            (Layer_scale): LayerScale()
          )
          (feed_forward): GCFN(
            (net1): Sequential(
              (0): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
              (1): Linear(in_features=128, out_features=768, bias=True)
            )
            (depthwise): Conv1d(768, 768, kernel_size=(3,), stride=(1,), padding=(1,), groups=768)
            (net2): Sequential(
              (0): GLU(dim=-1)
              (1): Dropout(p=0.05, inplace=False)
              (2): Linear(in_features=384, out_features=128, bias=True)
              (3): Dropout(p=0.05, inplace=False)
            )
            (Layer_scale): LayerScale()
          )
        )
      )
    )
  )
  (out_layer): OutputLayer(
    (spe_block): Masking(
      (gate_act): ReLU()
    )
    (end_conv1x1): Sequential(
      (0): Linear(in_features=128, out_features=512, bias=True)
      (1): GLU(dim=-1)
      (2): Linear(in_features=256, out_features=256, bias=True)
    )
  )
  (audio_decoder): AudioDecoder(256, 1, kernel_size=(16,), stride=(4,), bias=False)
  (out_layer_bn): ModuleList(
    (0-3): 4 x OutputLayer(
      (spe_block): Masking(
        (gate_act): ReLU()
      )
      (end_conv1x1): Sequential(
        (0): Linear(in_features=128, out_features=512, bias=True)
        (1): GLU(dim=-1)
        (2): Linear(in_features=256, out_features=256, bias=True)
      )
    )
  )
  (decoder_bn): ModuleList(
    (0-3): 4 x AudioDecoder(256, 1, kernel_size=(16,), stride=(4,), bias=False)
  )
), {'train': <torch.utils.data.dataloader.DataLoader object at 0x000002490B148130>, 'valid': <torch.utils.data.dataloader.DataLoader object at 0x000002490B148040>, 'test': <torch.utils.data.dataloader.DataLoader object at 0x000002490B148400>}, [<PIT_SISNR_mag(device=device(type='cuda', index=0), frame_length=512, frame_shift=128, window='hann', num_stages=4, num_spks=2, scale_inv=True, mel_opt=False, stft = [STFT instance for 4 layers], mel_fb=Identity)>, <PIT_SISNR_time(device=device(type='cuda', index=0), num_spks=2, scale_inv=True)>, <PIT_SISNRi(device=device(type='cuda', index=0), num_spks=2, scale_inv=True)>, <PIT_SDRi(device=device(type='cuda', index=0), dump=0)>], [AdamW (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.001
    lr: 0.0
    maximize: False
    weight_decay: 0.01
)], [<torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x000002490D3A8F10>, <WarmupConstantSchedule(optimizer=AdamW (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.001
    lr: 0.0
    maximize: False
    weight_decay: 0.01
), warmup_steps=1000, last_epoch=0, lr_lambda = <function WarmupConstantSchedule.__post_init__.<locals>.lr_lambda at 0x000002490B122B00>)>], (0,), device(type='cuda', index=0)), kwargs={})
2024-10-28 18:14:47.984 | INFO     | utils.util_engine:load_last_checkpoint_n_get_epoch:41 - Loaded Pretrained model from D:\PythonProject-RequiredCourse\4rdâ†‘ SyntheticDesign_AIalgorithm_WUJIASONG\SepReformer-main\models\SepReformer_Base_WSJ0\log\scratch_weights\epoch.0180.pth .....
2024-10-28 18:14:49.580 | INFO     | utils.util_engine:model_params_mac_summary:138 - ptflops: MACs: 45.13 GMac, Params: 14.69
2024-10-28 18:14:49.818 | INFO     | utils.util_engine:model_params_mac_summary:144 - thop: MACs: 43.958357248 GMac, Params: 14.592
2024-10-28 18:14:50.575 | INFO     | utils.util_engine:model_params_mac_summary:150 - torchinfo: MACs: 5235.347456 GMac, Params: 14.691584
2024-10-28 18:14:50.575 | INFO     | models.SepReformer_Base_WSJ0.engine:__init__:47 - Clip gradient by 2-norm 5
2024-10-28 18:14:50.575 | DEBUG    | models.SepReformer_Base_WSJ0.main:main:43 - Exiting 'Engine' (result=<models.SepReformer_Base_WSJ0.engine.Engine object at 0x000002490D3A8E80>)
2024-10-28 18:14:50.575 | DEBUG    | models.SepReformer_Base_WSJ0.main:main:45 - Entering '_inference_sample' (args=(<models.SepReformer_Base_WSJ0.engine.Engine object at 0x000002490D3A8E80>, './sample_wav/sample_WSJ.wav', './sample_out/'), kwargs={})
2024-10-28 18:14:56.929 | DEBUG    | models.SepReformer_Base_WSJ0.main:main:45 - Exiting '_inference_sample' (result=None)
2024-10-28 18:14:56.933 | DEBUG    | __main__:<module>:32 - Exiting 'main' (result=None)
