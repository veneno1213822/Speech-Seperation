config:
    dataset:
        max_len : 32000
        sampling_rate: 8000
        scp_dir: "data/scp_ss_8k_whamr"
        train:
            mixture: "tr_mix.scp"
            spk1: "tr_s1.scp"
            spk2: "tr_s2.scp"
            spk1_reverb: "tr_s1_reverb.scp"
            spk2_reverb: "tr_s2_reverb.scp"
            noise: "tr_n.scp"
            dynamic_mixing: true
        valid:
            mixture: "cv_mix.scp"
            spk1: "cv_s1.scp"
            spk2: "cv_s2.scp"
        test:
            mixture: "tt_mix.scp"
            spk1: "tt_s1.scp"
            spk2: "tt_s2.scp"
    dataloader:
        batch_size: 2
        pin_memory: false
        num_workers: 12
        drop_last: false
    model:
        num_stages: &var_model_num_stages 4 # R
        num_spks: &var_model_num_spks 2
        module_audio_enc:
            in_channels: 1
            out_channels: &var_model_audio_enc_out_channels 256
            kernel_size: &var_model_audio_enc_kernel_size 16 # L
            stride: &var_model_audio_enc_stride 4 # S
            groups: 1
            bias: false
        module_feature_projector:
            num_channels: *var_model_audio_enc_out_channels 
            in_channels: *var_model_audio_enc_out_channels
            out_channels: &feature_projector_out_channels 256 # F
            kernel_size: 1
            bias: false
        module_separator:
            num_stages: *var_model_num_stages
            relative_positional_encoding:
                in_channels: *feature_projector_out_channels
                num_heads: 8
                maxlen: 2000
                embed_v: false
            enc_stage:
                global_blocks:
                    in_channels: *feature_projector_out_channels
                    num_mha_heads: 8
                    dropout_rate: 0.1
                local_blocks:
                    in_channels: *feature_projector_out_channels
                    kernel_size: 65
                    dropout_rate: 0.1
                down_conv_layer:
                    in_channels: *feature_projector_out_channels
                    samp_kernel_size: &var_model_samp_kernel_size 5
            spk_split_stage:
                in_channels: *feature_projector_out_channels
                num_spks: *var_model_num_spks
            simple_fusion:
                out_channels: *feature_projector_out_channels
            dec_stage:
                num_spks: *var_model_num_spks
                global_blocks:
                    in_channels: *feature_projector_out_channels
                    num_mha_heads: 8
                    dropout_rate: 0.1
                local_blocks:
                    in_channels: *feature_projector_out_channels
                    kernel_size: 65
                    dropout_rate: 0.1
                spk_attention:
                    in_channels: *feature_projector_out_channels
                    num_mha_heads: 8
                    dropout_rate: 0.1
        module_output_layer:
            in_channels: *var_model_audio_enc_out_channels
            out_channels: *feature_projector_out_channels
            num_spks: *var_model_num_spks
        module_audio_dec:
            in_channels: *var_model_audio_enc_out_channels
            out_channels: 1
            kernel_size: *var_model_audio_enc_kernel_size
            stride: *var_model_audio_enc_stride
            bias: false
    criterion: ### Ref: https://pytorch.org/docs/stable/nn.html#loss-functions
        name: ["PIT_SISNR_mag", "PIT_SISNR_time", "PIT_SISNRi", "PIT_SDRi"] ### Choose a torch.nn's loss function class(=attribute) e.g. ["L1Loss", "MSELoss", "CrossEntropyLoss", ...] / You can also build your optimizer :)
        PIT_SISNR_mag:
            frame_length: 512
            frame_shift: 128
            window: 'hann'
            num_stages: *var_model_num_stages
            num_spks: *var_model_num_spks
            scale_inv: true
            mel_opt: false
        PIT_SISNR_time:
            num_spks: *var_model_num_spks
            scale_inv: true
        PIT_SISNRi:
            num_spks: *var_model_num_spks
            scale_inv: true
        PIT_SDRi:
            dump: 0
    optimizer: ### Ref: https://pytorch.org/docs/stable/optim.html#algorithms
        name: ["AdamW"] ### Choose a torch.optim's class(=attribute) e.g. ["Adam", "AdamW", "SGD", ...] / You can also build your optimizer :)
        AdamW:
            lr: 2.0e-4
            weight_decay: 1.0e-2
    scheduler: ### Ref(+ find "How to adjust learning rate"): https://pytorch.org/docs/stable/optim.html#algorithms
        name: ["ReduceLROnPlateau", "WarmupConstantSchedule"] ### Choose a torch.optim.lr_scheduler's class(=attribute) e.g. ["StepLR", "ReduceLROnPlateau", "Custom"] / You can also build your scheduler :)
        ReduceLROnPlateau:
            mode: "min"
            min_lr: 1.0e-10
            factor: 0.8
            patience: 2
        WarmupConstantSchedule:
            warmup_steps: 1000
    check_computations:
        dummy_len: 16000
    engine:
        max_epoch: 200
        gpuid: "0" ### "0"(single-gpu) or "0, 1" (multi-gpu)
        mvn: false
        clip_norm: 5
        start_scheduling: 100
        test_epochs: [100, 120, 150, 180, 200, 220, 240, 250, 260, 280, 290]
